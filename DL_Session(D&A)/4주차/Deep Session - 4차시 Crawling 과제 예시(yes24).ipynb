{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과제\n",
    "\n",
    "- yes24에서 python을 검색하고 200권의 책의 정보를 수집하는 코드를 작성하고, csv파일과 xlsx파일로 저장하시오  \n",
    "  (다른 책을 검색해도 됨 / 과제 예시는 python을 검색한 코드로 나갈 것)\n",
    "- 책사진, 제목, 저자, 가격, 판매지수, 회원리뷰수, 별점 점수, 사이크 링크를 모두 포함해야함\n",
    "- 책사진은 폴더를 따로 만들어 저장한 후 캡처본으로 제출\n",
    "- 패키지 이용에는 관여하지 않음\n",
    "- 제출 목록(4개) : 4차시과제_학번.ipynb파일, 4차시과제_학번.csv파일, 4차시과제_학번.excel파일, 4차시과제_학번.사진저장 폴더의 캡처본"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import time\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys # 스크롤 내리기\n",
    "\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Requests와 BeautifulSoup를 사용한 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page: 1, req status: 200\n",
      "page: 2, req status: 200\n",
      "page: 3, req status: 200\n",
      "page: 4, req status: 200\n",
      "page: 5, req status: 200\n",
      "page: 6, req status: 200\n",
      "page: 7, req status: 200\n",
      "page: 8, req status: 200\n",
      "page: 9, req status: 200\n",
      "page: 10, req status: 200\n",
      "Crawling Finished !\n"
     ]
    }
   ],
   "source": [
    "# 검색, 페이지\n",
    "keyword = 'python'; page =1\n",
    "# 스크랩한 책의 갯수\n",
    "total_books = 1\n",
    "# 제목 / 저자 /가격 / 판매지수 / 회원리뷰수 / 별점 점수 / 링크 리스트\n",
    "titles = []; writers = []; prices = []; sales_indexs = [];\n",
    "views = []; rating_scores = []; links = [];\n",
    "\n",
    "\n",
    "while total_books < 200:\n",
    "    req = requests.get(f'http://www.yes24.com/searchcorner/Search?keywordAd=&keyword=&domain=BOOK&qdomain=%b1%b9%b3%bb%b5%b5%bc%ad&query={keyword}&PageNumber={page}',headers={'User_Agent':'Mozilla/5.0'})\n",
    "    print(f'page: {page}, req status: {req.status_code}')\n",
    "\n",
    "    # html 구조로 인식\n",
    "    soup = BeautifulSoup(req.text, 'html.parser')\n",
    "    \n",
    "    # ----- image 저장\n",
    "    images = soup.select('td.goods_img')\n",
    "    for image in images:\n",
    "        image_src = image.select_one('a img').attrs['src']\n",
    "        urlretrieve(image_src, f'./product_pictures/beautifulSoup/python/{total_books}.jpg'); total_books +=1\n",
    "    # ----- 제목 / 저자 /가격 / 판매지수 / 회원리뷰수 / 별점 점수 / 링크 저장\n",
    "    books = soup.select('td.goods_infogrp')\n",
    "    for book in books:\n",
    "        title = book.select_one('p a').text\n",
    "        titles.append(title.replace(\",\", \"-\"))\n",
    "        if ' 저' in book.select_one('div.goods_info').text:\n",
    "            writer = book.select_one('div.goods_info').text.split(' 저')[0].strip('\\n')\n",
    "            writers.append(writer.replace(\",\", \"-\"))\n",
    "        elif ' 공저' in book.select_one('div.goods_info').text:\n",
    "            writer = book.select_one('div.goods_info').text.split(' 공저')[0].strip('\\n')\n",
    "            writers.append(writer.replace(\",\", \"-\"))\n",
    "        elif ' 편저' in book.select_one('div.goods_info').text:\n",
    "            writer = book.select_one('div.goods_info').text.split(' 편저')[0].strip('\\r\\n                ')\n",
    "            writers.append(writer.replace(\",\", \"-\"))\n",
    "        price = book.select_one('div.goods_price em').text\n",
    "        prices.append(price.replace(\",\", \"\"))\n",
    "        try:\n",
    "            sales_index = book.select_one('span.gd_reviewCount').text.split()[1]\n",
    "            sales_indexs.append(sales_index.replace(\",\", \"\"))\n",
    "        except:\n",
    "            sales_indexs.append('판매지수없음')\n",
    "        try:\n",
    "            view = book.select_one('div.goods_rating span a em').text\n",
    "            views.append(view.replace(\",\", \"\"))\n",
    "        except:\n",
    "            views.append('0')\n",
    "        try:\n",
    "            rating_score = book.select_one('span.gd_rating em').text\n",
    "            rating_scores.append(rating_score)\n",
    "        except:\n",
    "            rating_scores.append('별점미등록')\n",
    "        href = book.select_one('p a').attrs['href']\n",
    "        link = 'http://www.yes24.com' + href\n",
    "        links.append(link)\n",
    "    page += 1\n",
    "\n",
    "print('Crawling Finished !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# csv 파일로 저장\n",
    "f = open('yes24_csv_python.csv', 'w')\n",
    "f.write('제목, 저자, 가격, 판매지수, 회원리뷰수, 별점 점수, 링크 리스트\\n')\n",
    "for i in range(total_books-1):\n",
    "    f.write(f'{titles[i]}, {writers[i]}, {prices[i]}, {sales_indexs[i]}, {views[i]}, {rating_scores[i]}, {links[i]}\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel 파일로 저장\n",
    "wb = openpyxl.Workbook()\n",
    "sheet = wb.active\n",
    "sheet.append('제목, 저자, 가격, 판매지수, 회원리뷰수, 별점 점수, 링크 리스트'.split(','))\n",
    "for i in range(total_books-1):\n",
    "    sheet.append(f'{titles[i]}, {writers[i]}, {prices[i]}, {sales_indexs[i]}, {views[i]}, {rating_scores[i]}, {links[i]}'.split(','))\n",
    "wb.save('yes24_excel_python.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Selenium을 사용한 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드라이버 불러오기(크롬으로 빈 페이지가 불러와짐)\n",
    "dr = webdriver.Chrome('./chromedriver_win32/chromedriver')\n",
    "\n",
    "# 원하는 페이지 get메소드로 불러오기\n",
    "dr.get('http://www.yes24.com/')\n",
    "\n",
    "# 검색입력\n",
    "search_bar = dr.find_element_by_css_selector('span.schIpt label input')\n",
    "search_bar.send_keys('python')\n",
    "\n",
    "# 클릭하기\n",
    "search = dr.find_element_by_css_selector('span.schBtn button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page: 1\n",
      "page: 2\n",
      "page: 3\n",
      "page: 4\n",
      "page: 5\n",
      "page: 6\n",
      "page: 7\n",
      "page: 8\n",
      "page: 9\n",
      "page: 10\n",
      "Crawling Finished !\n"
     ]
    }
   ],
   "source": [
    "# 스크랩한 책의 갯수, 페이지\n",
    "total_books = 1; page = 1\n",
    "# 제목 / 저자 /가격 / 판매지수 / 회원리뷰수 / 별점 점수 / 링크 리스트\n",
    "titles = []; writers = []; prices = []; sales_indexs = [];\n",
    "views = []; rating_scores = []; links = [];\n",
    "\n",
    "while total_books < 200 :\n",
    "    # ----- 이미지 저장\n",
    "    images = dr.find_elements_by_css_selector('td.goods_img')[:20]\n",
    "    for image in images:\n",
    "        image_src = image.find_element_by_css_selector('a img').get_attribute('src')\n",
    "        urlretrieve(image_src, f'./product_pictures/selenium/python/{total_books}.jpg')\n",
    "        total_books +=1\n",
    "    # ----- 제목 / 저자 /가격 / 판매지수 / 회원리뷰수 / 별점 점수 / 링크 저장\n",
    "    books = dr.find_elements_by_css_selector('td.goods_infogrp')[:20]\n",
    "    for book in books:\n",
    "        title = book.find_element_by_css_selector('p a').text\n",
    "        titles.append(title.replace(\",\",\"-\"))\n",
    "        writer_infos = book.find_element_by_css_selector('div.goods_info').text\n",
    "        if ' 저' in writer_infos:\n",
    "            writer = writer_infos.split(' 저')[0]\n",
    "            writers.append(writer.replace(\",\",\"-\"))\n",
    "        elif ' 공저' in writer_infos:\n",
    "            writer = writer_infos.split(' 공저')[0]\n",
    "            writers.append(writer.replace(\",\",\"-\"))\n",
    "        elif ' 편저' in writer_infos:\n",
    "            writer = writer_infos.split(' 편저')[0]\n",
    "            writers.append(writer)\n",
    "        elif ' 역' in writer_infos:\n",
    "            writer = writer_infos.split(' 역')[0]\n",
    "            writers.append(writer)\n",
    "        else:\n",
    "            writer = writer_infos.split(' |')[0]\n",
    "            writers.append(writer.replace(\",\",\"-\"))\n",
    "        price = book.find_element_by_css_selector('div.goods_price em').text.replace(\",\", \"\")\n",
    "        prices.append(price.replace(\", \", \"\"))\n",
    "        try:\n",
    "            sales_index = book.find_element_by_css_selector('div.goods_rating > span').text.split()[1]\n",
    "            sales_indexs.append(sales_index.replace(\",\",\"\"))\n",
    "        except:\n",
    "            sales_indexs.append('판매지수없음')\n",
    "        try:\n",
    "            view = book.find_element_by_css_selector('div.goods_rating span a em').text.replace(\", \", \"\")\n",
    "            views.append(view.replace(\",\",\"\"))\n",
    "        except:\n",
    "            views.append('0')\n",
    "        try:\n",
    "            rating_score = book.find_element_by_css_selector('span.gd_rating em').text\n",
    "            rating_scores.append(rating_score)\n",
    "        except:\n",
    "            rating_scores.append('별점미등록')\n",
    "        link = book.find_element_by_css_selector('p a').get_attribute('href')\n",
    "        links.append(link)\n",
    "    print(f'page: {page}')\n",
    "    page += 1\n",
    "    try:\n",
    "        next_page = dr.find_element_by_css_selector(f'a.n:nth-of-type({page+1})')\n",
    "        next_page.click()\n",
    "        time.sleep(1.5)\n",
    "    except:\n",
    "        break\n",
    "\n",
    "print('Crawling Finished !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# csv 파일로 저장\n",
    "f = open('yes24_csv_python_selenium.csv', 'w')\n",
    "f.write('제목, 저자, 가격, 판매지수, 회원리뷰수, 별점 점수, 링크 리스트\\n')\n",
    "for i in range(total_books-1):\n",
    "    f.write(f'{titles[i]}, {writers[i]}, {prices[i]}, {sales_indexs[i]}, {views[i]}, {rating_scores[i]}, {links[i]}\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel 파일로 저장\n",
    "wb = openpyxl.Workbook()\n",
    "sheet = wb.active\n",
    "sheet.append('제목, 저자, 가격, 판매지수, 회원리뷰수, 별점 점수, 링크 리스트'.split(','))\n",
    "for i in range(total_books-1):\n",
    "    sheet.append(f'{titles[i]}, {writers[i]}, {prices[i]}, {sales_indexs[i]}, {views[i]}, {rating_scores[i]}, {links[i]}'.split(','))\n",
    "wb.save('yes24_excel_python_selenium.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fin───────────────────────────────────────────────────────────────────────────────────────────────**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
